import os
import cv2
import torch
import glob
import platform
from pathlib import Path
from ultralytics import YOLO
import matplotlib.pyplot as plt
import numpy as np

# ==================== å…¨å±€é…ç½®å˜é‡ ====================
# ç¥ç»ç½‘ç»œé…ç½®
MODEL_SIZE = "s"  # å¯é€‰: "n", "s", "m", "l", "x" - æ§åˆ¶æ¨¡å‹å¤§å°å’Œå±‚æ•°
MODEL_TYPE = "detect"  # ä»»åŠ¡ç±»å‹: "detect", "segment", "classify"

# è®­ç»ƒé…ç½®
TRAIN_EPOCHS = 100
TRAIN_IMGSZ = 640
TRAIN_BATCH = 8
TRAIN_LEARNING_RATE = 0.01

# æ¨ç†é…ç½®
INFERENCE_CONF = 0.25  # ç½®ä¿¡åº¦é˜ˆå€¼
INFERENCE_IOU = 0.45   # IOUé˜ˆå€¼

# è·¯å¾„é…ç½®
PROJECT_NAME = "FireDetection"

# è®¾å¤‡é…ç½®
AUTO_DEVICE = True  # è‡ªåŠ¨é€‰æ‹©è®¾å¤‡
FORCE_CPU = False   # å¼ºåˆ¶ä½¿ç”¨CPU

# ==================== æ¨¡å‹å±‚æ•°æ˜ å°„ ====================
MODEL_ARCHITECTURE = {
    "n": {
        "name": "YOLOv8n",
        "layers": 168,
        "parameters": "3.2M",
        "description": "è½»é‡çº§ - æœ€å¿«é€Ÿåº¦"
    },
    "s": {
        "name": "YOLOv8s", 
        "layers": 168,
        "parameters": "11.2M",
        "description": "å°æ¨¡å‹ - å¹³è¡¡é€Ÿåº¦ç²¾åº¦"
    },
    "m": {
        "name": "YOLOv8m",
        "layers": 218,
        "parameters": "25.9M",
        "description": "ä¸­æ¨¡å‹ - æ¨èä½¿ç”¨"
    },
    "l": {
        "name": "YOLOv8l",
        "layers": 268,
        "parameters": "43.7M",
        "description": "å¤§æ¨¡å‹ - é«˜ç²¾åº¦"
    },
    "x": {
        "name": "YOLOv8x",
        "layers": 268,
        "parameters": "68.2M",
        "description": "è¶…å¤§æ¨¡å‹ - æœ€é«˜ç²¾åº¦"
    }
}

class CrossPlatformForestFireDetector:
    def __init__(self, model_path=None):
        """
        åˆå§‹åŒ–è·¨å¹³å°æ£®æ—ç«ç¾æ£€æµ‹å™¨
        """
        self.conf_threshold = INFERENCE_CONF
        self.model = None
        self.system_info = self.get_system_info()
        self.setup_environment()
        self.load_model(model_path)
    
    def get_system_info(self):
        """è·å–ç³»ç»Ÿä¿¡æ¯"""
        system = platform.system()
        info = {
            "system": system,
            "is_windows": system == "Windows",
            "is_mac": system == "Darwin",
            "is_linux": system == "Linux",
            "architecture": platform.architecture()[0],
            "processor": platform.processor()
        }
        return info
    
    def setup_environment(self):
        """è®¾ç½®è·¨å¹³å°ç¯å¢ƒ"""
        print("=" * 60)
        print("ğŸŒ² æ£®æ—ç«ç¾è¯†åˆ«ç³»ç»Ÿ - è·¨å¹³å°ç‰ˆ")
        print("=" * 60)
        
        # æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯
        print(f"ğŸ’» æ“ä½œç³»ç»Ÿ: {self.system_info['system']}")
        print(f"ğŸ”§ å¤„ç†å™¨: {self.system_info['processor']}")
        print(f"ğŸ“Š æ¶æ„: {self.system_info['architecture']}")
        
        # æ˜¾ç¤ºæ¨¡å‹é…ç½®
        model_config = MODEL_ARCHITECTURE.get(MODEL_SIZE, MODEL_ARCHITECTURE["s"])
        print(f"ğŸ¤– æ¨¡å‹é…ç½®: {model_config['name']}")
        print(f"ğŸ“ˆ ç½‘ç»œå±‚æ•°: {model_config['layers']}å±‚")
        print(f"ğŸ’¾ å‚æ•°é‡: {model_config['parameters']}")
        print(f"ğŸ¯ ç‰¹ç‚¹: {model_config['description']}")
        
        # è®¾å¤‡æ£€æµ‹å’Œé€‰æ‹©
        self.device = self.select_device()
        
        # è®¾ç½®è·¨å¹³å°å·¥ä½œç›®å½•
        self.setup_cross_platform_paths()
        
        print("âœ… ç¯å¢ƒåˆå§‹åŒ–å®Œæˆ")
    
    def select_device(self):
        """é€‰æ‹©è®¡ç®—è®¾å¤‡"""
        if FORCE_CPU:
            print("âš ï¸ å¼ºåˆ¶ä½¿ç”¨CPUæ¨¡å¼")
            return "cpu"
        
        if not AUTO_DEVICE:
            print("âš ï¸ æ‰‹åŠ¨è®¾å¤‡é€‰æ‹©æ¨¡å¼")
            return 0  # é»˜è®¤
        
        # è‡ªåŠ¨è®¾å¤‡é€‰æ‹©
        if torch.cuda.is_available():
            gpu_name = torch.cuda.get_device_name(0)
            print(f"ğŸ¯ æ£€æµ‹åˆ°CUDA GPU: {gpu_name}")
            return 0
        elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            print("ğŸ æ£€æµ‹åˆ°Apple Silicon MPS")
            return "mps"
        else:
            print("âš ï¸ ä½¿ç”¨CPUè¿›è¡Œæ¨ç†")
            return "cpu"
    
    def setup_cross_platform_paths(self):
        """è®¾ç½®è·¨å¹³å°è·¯å¾„"""
        # ä½¿ç”¨å¹³å°ç‰¹å®šçš„è·¯å¾„
        if self.system_info['is_windows']:
            # Windows: ä½¿ç”¨ç”¨æˆ·æ–‡æ¡£ç›®å½•
            self.home_dir = str(Path.home() / "Documents" / PROJECT_NAME)
        elif self.system_info['is_mac']:
            # Mac: ä½¿ç”¨ç”¨æˆ·ä¸»ç›®å½•
            self.home_dir = str(Path.home() / PROJECT_NAME)
        else:
            # Linuxå’Œå…¶ä»–ç³»ç»Ÿ
            self.home_dir = str(Path.home() / PROJECT_NAME)
        
        # åˆ›å»ºå¿…è¦çš„ç›®å½•
        directories = [
            self.home_dir,
            f"{self.home_dir}/results",
            f"{self.home_dir}/datasets",
            f"{self.home_dir}/models",
            f"{self.home_dir}/exports"
        ]
        
        for directory in directories:
            os.makedirs(directory, exist_ok=True)
        
        print(f"ğŸ“ å·¥ä½œç›®å½•: {self.home_dir}")
    
    def get_model_path(self, model_path=None):
        """è·å–æ¨¡å‹è·¯å¾„ï¼ˆè·¨å¹³å°å…¼å®¹ï¼‰"""
        if model_path and os.path.exists(model_path):
            return model_path
        
        # æ£€æŸ¥å·¥ä½œç›®å½•ä¸­çš„æ¨¡å‹
        local_model_path = f"{self.home_dir}/models/best.pt"
        if os.path.exists(local_model_path):
            return local_model_path
        
        # ä½¿ç”¨å…¨å±€é…ç½®çš„æ¨¡å‹
        model_name = f"yolov8{MODEL_SIZE}.pt"
        return model_name
    
    def load_model(self, model_path=None):
        """
        åŠ è½½YOLOv8æ¨¡å‹
        """
        try:
            final_model_path = self.get_model_path(model_path)
            
            if final_model_path.endswith('.pt') and os.path.exists(final_model_path):
                print(f"ğŸ”§ åŠ è½½è‡ªå®šä¹‰æ¨¡å‹: {final_model_path}")
                self.model = YOLO(final_model_path)
            else:
                print(f"ğŸ”§ åŠ è½½é¢„è®­ç»ƒæ¨¡å‹: yolov8{MODEL_SIZE}.pt")
                self.model = YOLO(f'yolov8{MODEL_SIZE}.pt')
            
            print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!")
            
            # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
            if hasattr(self.model, 'model'):
                if hasattr(self.model.model, 'nc'):
                    print(f"ğŸ¯ æ¨¡å‹ç±»åˆ«æ•°: {self.model.model.nc}")
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            # å°è¯•åŠ è½½åŸºç¡€æ¨¡å‹ä½œä¸ºå¤‡ç”¨
            try:
                print("ğŸ”„ å°è¯•åŠ è½½åŸºç¡€YOLOv8næ¨¡å‹...")
                self.model = YOLO('yolov8n.pt')
                print("âœ… å¤‡ç”¨æ¨¡å‹åŠ è½½æˆåŠŸ!")
            except Exception as e2:
                print(f"âŒ æ‰€æœ‰æ¨¡å‹åŠ è½½å°è¯•éƒ½å¤±è´¥: {e2}")
    
    def detect_image(self, image_path, save=True, show=True):
        """
        å¯¹å•å¼ å›¾åƒè¿›è¡Œç«ç¾æ£€æµ‹
        """
        print(f"ğŸ–¼ï¸ å¤„ç†å›¾åƒ: {image_path}")
        
        # è·¨å¹³å°è·¯å¾„å¤„ç†
        image_path = self.normalize_path(image_path)
        
        if not os.path.exists(image_path):
            print(f"âŒ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
            return None
        
        try:
            # æ‰§è¡Œæ¨ç†
            results = self.model.predict(
                source=image_path,
                conf=self.conf_threshold,
                iou=INFERENCE_IOU,
                save=save,
                save_txt=True,
                save_conf=True,
                device=self.device
            )
            
            # æ˜¾ç¤ºç»“æœ
            if show and len(results) > 0:
                result = results[0]
                self.display_detection_result(result, image_path)
            
            return results
            
        except Exception as e:
            print(f"âŒ å›¾åƒæ£€æµ‹å¤±è´¥: {e}")
            return None
    
    def detect_video(self, video_path, output_path=None):
        """
        å¯¹è§†é¢‘è¿›è¡Œç«ç¾æ£€æµ‹
        """
        print(f"ğŸ¥ å¤„ç†è§†é¢‘: {video_path}")
        
        video_path = self.normalize_path(video_path)
        
        if not os.path.exists(video_path):
            print(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
            return None
        
        if output_path is None:
            video_name = Path(video_path).stem
            output_path = f"{self.home_dir}/results/{video_name}_detected.mp4"
        
        try:
            # æ‰§è¡Œè§†é¢‘æ¨ç†
            results = self.model.predict(
                source=video_path,
                conf=self.conf_threshold,
                save=True,
                project=f"{self.home_dir}/results",
                name="video_detection",
                device=self.device
            )
            
            print(f"âœ… è§†é¢‘å¤„ç†å®Œæˆ: {output_path}")
            return results
            
        except Exception as e:
            print(f"âŒ è§†é¢‘æ£€æµ‹å¤±è´¥: {e}")
            return None
    
    def detect_webcam(self, camera_id=0):
        """
        ä½¿ç”¨æ‘„åƒå¤´è¿›è¡Œå®æ—¶ç«ç¾æ£€æµ‹
        """
        print("ğŸ“¹ å¯åŠ¨æ‘„åƒå¤´å®æ—¶æ£€æµ‹...")
        
        # åœ¨Windowsä¸Šå¯èƒ½éœ€è¦ä¸åŒçš„åç«¯
        if self.system_info['is_windows']:
            cap = cv2.VideoCapture(camera_id, cv2.CAP_DSHOW)
        else:
            cap = cv2.VideoCapture(camera_id)
        
        if not cap.isOpened():
            print("âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
            # å°è¯•å…¶ä»–æ‘„åƒå¤´ID
            for i in range(1, 5):
                cap = cv2.VideoCapture(i)
                if cap.isOpened():
                    print(f"âœ… æ‰¾åˆ°æ‘„åƒå¤´ ID: {i}")
                    break
            else:
                print("âŒ æœªæ‰¾åˆ°å¯ç”¨çš„æ‘„åƒå¤´")
                return
        
        print("ğŸ¯ æŒ‰ 'q' é”®é€€å‡ºå®æ—¶æ£€æµ‹")
        print("ğŸ¯ æŒ‰ 's' é”®ä¿å­˜å½“å‰å¸§")
        
        frame_count = 0
        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    print("âŒ æ— æ³•è¯»å–æ‘„åƒå¤´ç”»é¢")
                    break
                
                # æ‰§è¡Œæ¨ç†
                results = self.model(frame, conf=self.conf_threshold, device=self.device)
                
                # ç»˜åˆ¶æ£€æµ‹ç»“æœ
                annotated_frame = results[0].plot()
                
                # æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯
                fps = cap.get(cv2.CAP_PROP_FPS)
                status_text = [
                    f"FPS: {fps:.1f}",
                    f"Device: {self.device}",
                    f"Model: YOLOv8{MODEL_SIZE}",
                    "Press 'q' to quit, 's' to save"
                ]
                
                for i, text in enumerate(status_text):
                    y_position = 30 + i * 25
                    cv2.putText(annotated_frame, text, (10, y_position), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
                
                # æ˜¾ç¤ºç»“æœ
                cv2.imshow('æ£®æ—ç«ç¾å®æ—¶æ£€æµ‹ - Cross Platform', annotated_frame)
                
                # æŒ‰é”®å¤„ç†
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    break
                elif key == ord('s'):
                    # ä¿å­˜å½“å‰å¸§
                    save_path = f"{self.home_dir}/results/capture_{frame_count:04d}.jpg"
                    cv2.imwrite(save_path, annotated_frame)
                    print(f"ğŸ’¾ ä¿å­˜æˆªå›¾: {save_path}")
                    frame_count += 1
        
        finally:
            cap.release()
            cv2.destroyAllWindows()
    
    def normalize_path(self, path):
        """æ ‡å‡†åŒ–è·¯å¾„ï¼ˆè·¨å¹³å°å…¼å®¹ï¼‰"""
        return str(Path(path))
    
    def display_detection_result(self, result, image_path):
        """
        æ˜¾ç¤ºæ£€æµ‹ç»“æœ
        """
        boxes = result.boxes
        if boxes is not None and len(boxes) > 0:
            print(f"ğŸ”¥ æ£€æµ‹åˆ° {len(boxes)} ä¸ªç«ç¾åŒºåŸŸ:")
            
            for i, box in enumerate(boxes):
                cls = int(box.cls[0])
                conf = float(box.conf[0])
                coords = box.xyxy[0].cpu().numpy()
                
                class_name = "ç«ç¾" if cls == 0 else f"ç±»åˆ«{cls}"
                print(f"  åŒºåŸŸ {i+1}: {class_name}, ç½®ä¿¡åº¦={conf:.4f}")
        else:
            print("âœ… æœªæ£€æµ‹åˆ°ç«ç¾")
        
        # æ˜¾ç¤ºç»“æœæ–‡ä»¶è·¯å¾„
        if hasattr(result, 'save_dir'):
            result_image_path = f"{result.save_dir}/{os.path.basename(image_path)}"
            if os.path.exists(result_image_path):
                print(f"ğŸ’¾ ç»“æœå›¾åƒå·²ä¿å­˜: {result_image_path}")
                
                # åœ¨ä¸åŒå¹³å°ä¸Šå°è¯•æ‰“å¼€å›¾åƒ
                if self.system_info['is_windows']:
                    os.system(f'start "" "{result_image_path}"')
                elif self.system_info['is_mac']:
                    os.system(f'open "{result_image_path}"')
                elif self.system_info['is_linux']:
                    os.system(f'xdg-open "{result_image_path}"')
    
    def batch_detect(self, images_dir, output_dir=None):
        """
        æ‰¹é‡æ£€æµ‹å›¾åƒ
        """
        print(f"ğŸ“ æ‰¹é‡å¤„ç†ç›®å½•: {images_dir}")
        
        images_dir = self.normalize_path(images_dir)
        
        if not os.path.exists(images_dir):
            print(f"âŒ å›¾åƒç›®å½•ä¸å­˜åœ¨: {images_dir}")
            return []
        
        if output_dir is None:
            output_dir = f"{self.home_dir}/results/batch_detection"
        os.makedirs(output_dir, exist_ok=True)
        
        # è·¨å¹³å°å›¾åƒæ ¼å¼æ”¯æŒ
        image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.tiff', '*.webp']
        image_paths = []
        
        for extension in image_extensions:
            image_paths.extend(glob.glob(f"{images_dir}/{extension}"))
            # å¤„ç†å¤§å†™æ‰©å±•å
            image_paths.extend(glob.glob(f"{images_dir}/{extension.upper()}"))
        
        print(f"ğŸ“Š æ‰¾åˆ° {len(image_paths)} å¼ å›¾åƒ")
        
        all_results = []
        for i, image_path in enumerate(image_paths):
            print(f"ğŸ” å¤„ç†å›¾åƒ {i+1}/{len(image_paths)}: {os.path.basename(image_path)}")
            results = self.detect_image(image_path, save=True, show=False)
            all_results.append((image_path, results))
        
        self.generate_report(all_results)
        return all_results
    
    def generate_report(self, results):
        """
        ç”Ÿæˆæ£€æµ‹æŠ¥å‘Š
        """
        print("\n" + "="*60)
        print("ğŸ“Š æ£®æ—ç«ç¾æ£€æµ‹æŠ¥å‘Š - è·¨å¹³å°ç‰ˆ")
        print("="*60)
        
        total_images = len(results)
        fire_detected = 0
        total_fires = 0
        
        for image_path, result in results:
            if result and len(result) > 0 and result[0].boxes is not None:
                fire_count = len(result[0].boxes)
                if fire_count > 0:
                    fire_detected += 1
                    total_fires += fire_count
        
        # æ˜¾ç¤ºæŠ¥å‘Š
        model_info = MODEL_ARCHITECTURE.get(MODEL_SIZE, MODEL_ARCHITECTURE["s"])
        
        print(f"ğŸ¤– æ¨¡å‹ä¿¡æ¯: {model_info['name']}")
        print(f"ğŸ’» è¿è¡Œå¹³å°: {self.system_info['system']}")
        print(f"âš¡ è®¡ç®—è®¾å¤‡: {self.device}")
        print(f"ğŸ“ å¤„ç†å›¾åƒæ€»æ•°: {total_images}")
        print(f"ğŸ”¥ æ£€æµ‹åˆ°ç«ç¾çš„å›¾åƒ: {fire_detected}")
        print(f"ğŸ”¥ æ€»ç«ç¾åŒºåŸŸæ•°: {total_fires}")
        
        if total_images > 0:
            detection_rate = (fire_detected / total_images) * 100
            print(f"ğŸ“ˆ ç«ç¾æ£€æµ‹ç‡: {detection_rate:.2f}%")
        
        print("="*60)

def show_model_options():
    """æ˜¾ç¤ºæ¨¡å‹é€‰é¡¹"""
    print("\nğŸ¤– å¯ç”¨çš„ç¥ç»ç½‘ç»œé…ç½®:")
    print("-" * 50)
    for size, info in MODEL_ARCHITECTURE.items():
        current = " â† å½“å‰" if size == MODEL_SIZE else ""
        print(f"{size.upper()}: {info['name']} - {info['description']}{current}")
        print(f"    å±‚æ•°: {info['layers']}, å‚æ•°: {info['parameters']}")
    print("-" * 50)

def main():
    """ä¸»å‡½æ•°"""
    # æ˜¾ç¤ºæ¨¡å‹é€‰é¡¹
    show_model_options()
    
    # åˆå§‹åŒ–æ£€æµ‹å™¨
    detector = CrossPlatformForestFireDetector()
    
    while True:
        print(f"\nå½“å‰æ¨¡å‹: YOLOv8{MODEL_SIZE.upper()} - {MODEL_ARCHITECTURE[MODEL_SIZE]['description']}")
        print("\nè¯·é€‰æ‹©æ“ä½œ:")
        print("1. ğŸ–¼ï¸ å›¾åƒæ£€æµ‹")
        print("2. ğŸ¥ è§†é¢‘æ£€æµ‹") 
        print("3. ğŸ“¹ å®æ—¶æ‘„åƒå¤´æ£€æµ‹")
        print("4. ğŸ“ æ‰¹é‡å›¾åƒæ£€æµ‹")
        print("5. âš™ï¸ æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯")
        print("6. ğŸ¤– æ˜¾ç¤ºæ¨¡å‹é€‰é¡¹")
        print("0. âŒ é€€å‡º")
        
        choice = input("è¯·è¾“å…¥é€‰æ‹© (0-6): ").strip()
        
        if choice == '1':
            image_path = input("è¯·è¾“å…¥å›¾åƒè·¯å¾„: ").strip()
            detector.detect_image(image_path)
        
        elif choice == '2':
            video_path = input("è¯·è¾“å…¥è§†é¢‘è·¯å¾„: ").strip()
            detector.detect_video(video_path)
        
        elif choice == '3':
            detector.detect_webcam()
        
        elif choice == '4':
            images_dir = input("è¯·è¾“å…¥å›¾åƒç›®å½•è·¯å¾„: ").strip()
            detector.batch_detect(images_dir)
        
        elif choice == '5':
            print(f"\nğŸ’» ç³»ç»Ÿä¿¡æ¯:")
            for key, value in detector.system_info.items():
                print(f"  {key}: {value}")
            print(f"  è®¡ç®—è®¾å¤‡: {detector.device}")
        
        elif choice == '6':
            show_model_options()
        
        elif choice == '0':
            print("ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨è·¨å¹³å°æ£®æ—ç«ç¾è¯†åˆ«ç³»ç»Ÿ!")
            break
        
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")

if __name__ == "__main__":
    main()
"""
æ—ç«è¯†åˆ«æ¨¡å‹è®­ç»ƒè„šæœ¬ - YOLOv8 Custom Training
Forest Fire Detection Model Training Script
"""

import os
import yaml
import torch
import argparse
from pathlib import Path
from ultralytics import YOLO
import matplotlib.pyplot as plt
import numpy as np

# ==================== è®­ç»ƒé…ç½® ====================
class TrainingConfig:
    # æ¨¡å‹é…ç½®
    MODEL_SIZE = "s"  # å¯é€‰: "n", "s", "m", "l", "x"
    PRETRAINED_MODEL = True  # æ˜¯å¦ä½¿ç”¨é¢„è®­ç»ƒæƒé‡
    
    # è®­ç»ƒå‚æ•°
    EPOCHS = 150
    IMAGE_SIZE = 640
    BATCH_SIZE = 16
    LEARNING_RATE = 0.01
    PATIENCE = 25  # æ—©åœè€å¿ƒå€¼
    
    # æ•°æ®å¢å¼º
    AUGMENT = True
    HSV_H = 0.015  # è‰²è°ƒå¢å¼º
    HSV_S = 0.7    # é¥±å’Œåº¦å¢å¼º  
    HSV_V = 0.4    # äº®åº¦å¢å¼º
    FLIP_LR = 0.5  # å·¦å³ç¿»è½¬æ¦‚ç‡
    
    # ä¼˜åŒ–å™¨
    OPTIMIZER = "AdamW"  # SGD, Adam, AdamW, RMSprop
    WEIGHT_DECAY = 0.0005
    MOMENTUM = 0.937
    
    # è·¯å¾„é…ç½®
    PROJECT_NAME = "ForestFireDetection"
    DATASET_DIR = "datasets/fire_dataset"  # æ•°æ®é›†è·¯å¾„
    
    # è®¾å¤‡é…ç½®
    DEVICE = "auto"  # "auto", "cpu", "cuda", "mps" æˆ– 0,1,2,3

class ForestFireTrainer:
    def __init__(self, config):
        self.config = config
        self.model = None
        self.setup_environment()
        
    def setup_environment(self):
        """è®¾ç½®è®­ç»ƒç¯å¢ƒ"""
        print("=" * 60)
        print("ğŸ”¥ æ—ç«è¯†åˆ«æ¨¡å‹è®­ç»ƒç³»ç»Ÿ")
        print("=" * 60)
        
        # æ˜¾ç¤ºè®­ç»ƒé…ç½®
        self.print_training_config()
        
        # è®¾ç½®è®¾å¤‡
        self.device = self.setup_device()
        
        # åˆ›å»ºç›®å½•ç»“æ„
        self.setup_directories()
        
        # æ£€æŸ¥æ•°æ®é›†
        self.check_dataset()
        
    def print_training_config(self):
        """æ‰“å°è®­ç»ƒé…ç½®"""
        print("ğŸ“‹ è®­ç»ƒé…ç½®:")
        print(f"  ğŸ¤– æ¨¡å‹: YOLOv8{self.config.MODEL_SIZE.upper()}")
        print(f"  ğŸ“Š è®­ç»ƒè½®æ•°: {self.config.EPOCHS}")
        print(f"  ğŸ–¼ï¸ å›¾åƒå°ºå¯¸: {self.config.IMAGE_SIZE}")
        print(f"  ğŸ“¦ æ‰¹å¤§å°: {self.config.BATCH_SIZE}")
        print(f"  ğŸ“ˆ å­¦ä¹ ç‡: {self.config.LEARNING_RATE}")
        print(f"  ğŸ”„ æ•°æ®å¢å¼º: {self.config.AUGMENT}")
        print(f"  âš¡ ä¼˜åŒ–å™¨: {self.config.OPTIMIZER}")
        
    def setup_device(self):
        """è®¾ç½®è®­ç»ƒè®¾å¤‡"""
        if self.config.DEVICE == "auto":
            if torch.cuda.is_available():
                device = 0
                print(f"ğŸ¯ ä½¿ç”¨GPU: {torch.cuda.get_device_name(0)}")
            elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                device = "mps"
                print("ğŸ ä½¿ç”¨Apple Silicon MPS")
            else:
                device = "cpu"
                print("âš ï¸ ä½¿ç”¨CPUè®­ç»ƒï¼Œé€Ÿåº¦è¾ƒæ…¢")
        else:
            device = self.config.DEVICE
            print(f"ğŸ”§ ä½¿ç”¨æŒ‡å®šè®¾å¤‡: {device}")
            
        return device
    
    def setup_directories(self):
        """åˆ›å»ºç›®å½•ç»“æ„"""
        # é¡¹ç›®æ ¹ç›®å½•
        self.project_dir = Path.home() / self.config.PROJECT_NAME
        self.project_dir.mkdir(exist_ok=True)
        
        # å­ç›®å½•
        directories = [
            self.project_dir / "datasets",
            self.project_dir / "models",
            self.project_dir / "results",
            self.project_dir / "exports"
        ]
        
        for dir_path in directories:
            dir_path.mkdir(exist_ok=True)
            
        print(f"ğŸ“ é¡¹ç›®ç›®å½•: {self.project_dir}")
    
    def check_dataset(self):
        """æ£€æŸ¥æ•°æ®é›†å®Œæ•´æ€§"""
        dataset_path = self.project_dir / self.config.DATASET_DIR
        
        if not dataset_path.exists():
            print(f"âŒ æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {dataset_path}")
            print("è¯·å°†æ•°æ®é›†æ”¾ç½®åœ¨ä»¥ä¸‹ç›®å½•ç»“æ„:")
            print(f"""
            {dataset_path}/
            â”œâ”€â”€ train/
            â”‚   â”œâ”€â”€ images/
            â”‚   â””â”€â”€ labels/
            â”œâ”€â”€ val/
            â”‚   â”œâ”€â”€ images/
            â”‚   â””â”€â”€ labels/
            â”œâ”€â”€ test/
            â”‚   â”œâ”€â”€ images/
            â”‚   â””â”€â”€ labels/
            â””â”€â”€ data.yaml
            """)
            return False
        
        # æ£€æŸ¥å¿…è¦çš„æ–‡ä»¶å’Œç›®å½•
        required_paths = [
            dataset_path / "data.yaml",
            dataset_path / "train/images",
            dataset_path / "train/labels", 
            dataset_path / "val/images",
            dataset_path / "val/labels"
        ]
        
        for path in required_paths:
            if not path.exists():
                print(f"âŒ ç¼ºå¤±å¿…è¦æ–‡ä»¶/ç›®å½•: {path}")
                return False
        
        # æ£€æŸ¥æ•°æ®YAMLæ–‡ä»¶
        try:
            with open(dataset_path / "data.yaml", 'r') as f:
                data_cfg = yaml.safe_load(f)
            
            print("âœ… æ•°æ®é›†é…ç½®:")
            print(f"  ç±»åˆ«æ•°: {data_cfg.get('nc', 'æœªçŸ¥')}")
            print(f"  ç±»åˆ«åç§°: {data_cfg.get('names', 'æœªçŸ¥')}")
            print(f"  è®­ç»ƒå›¾åƒ: {len(list((dataset_path / 'train/images').glob('*')))}")
            print(f"  éªŒè¯å›¾åƒ: {len(list((dataset_path / 'val/images').glob('*')))}")
            
            if (dataset_path / "test/images").exists():
                print(f"  æµ‹è¯•å›¾åƒ: {len(list((dataset_path / 'test/images').glob('*')))}")
                
        except Exception as e:
            print(f"âŒ æ•°æ®é…ç½®æ–‡ä»¶é”™è¯¯: {e}")
            return False
            
        self.dataset_path = dataset_path
        return True
    
    def analyze_dataset(self):
        """åˆ†ææ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯"""
        print("\nğŸ“Š æ•°æ®é›†åˆ†æ:")
        
        # åˆ†æè®­ç»ƒé›†æ ‡æ³¨
        train_labels_dir = self.dataset_path / "train/labels"
        if train_labels_dir.exists():
            label_files = list(train_labels_dir.glob("*.txt"))
            
            if label_files:
                class_counts = {}
                total_objects = 0
                
                for label_file in label_files:
                    with open(label_file, 'r') as f:
                        for line in f:
                            if line.strip():
                                class_id = int(line.strip().split()[0])
                                class_counts[class_id] = class_counts.get(class_id, 0) + 1
                                total_objects += 1
                
                print(f"  æ€»æ ‡æ³¨å¯¹è±¡: {total_objects}")
                print(f"  ç±»åˆ«åˆ†å¸ƒ: {class_counts}")
                
                # è¯»å–ç±»åˆ«åç§°
                with open(self.dataset_path / "data.yaml", 'r') as f:
                    data_cfg = yaml.safe_load(f)
                
                if 'names' in data_cfg:
                    for class_id, count in class_counts.items():
                        class_name = data_cfg['names'].get(class_id, f'class_{class_id}')
                        print(f"    {class_name}: {count} ä¸ªå®ä¾‹")
    
    def create_model(self):
        """åˆ›å»ºæ¨¡å‹"""
        print("\nğŸ¤– åˆ›å»ºæ¨¡å‹...")
        
        if self.config.PRETRAINED_MODEL:
            # ä½¿ç”¨é¢„è®­ç»ƒæƒé‡
            model_name = f"yolov8{self.config.MODEL_SIZE}.pt"
            print(f"  åŠ è½½é¢„è®­ç»ƒæ¨¡å‹: {model_name}")
            self.model = YOLO(model_name)
        else:
            # ä»é›¶å¼€å§‹è®­ç»ƒ
            model_name = f"yolov8{self.config.MODEL_SIZE}.yaml"
            print(f"  ä»é›¶å¼€å§‹è®­ç»ƒ: {model_name}")
            self.model = YOLO(model_name)
        
        print("âœ… æ¨¡å‹åˆ›å»ºå®Œæˆ")
    
    def setup_training_arguments(self):
        """è®¾ç½®è®­ç»ƒå‚æ•°"""
        args = {
            # åŸºç¡€é…ç½®
            'data': str(self.dataset_path / "data.yaml"),
            'epochs': self.config.EPOCHS,
            'imgsz': self.config.IMAGE_SIZE,
            'batch': self.config.BATCH_SIZE,
            'patience': self.config.PATIENCE,
            
            # ä¼˜åŒ–å™¨é…ç½®
            'lr0': self.config.LEARNING_RATE,
            'lrf': 0.01,  # æœ€ç»ˆå­¦ä¹ ç‡å€æ•°
            'momentum': self.config.MOMENTUM,
            'weight_decay': self.config.WEIGHT_DECAY,
            'optimizer': self.config.OPTIMIZER,
            
            # æ•°æ®å¢å¼º
            'hsv_h': self.config.HSV_H,
            'hsv_s': self.config.HSV_S,
            'hsv_v': self.config.HSV_V,
            'fliplr': self.config.FLIP_LR,
            'mosaic': 1.0,  # mosaicæ•°æ®å¢å¼º
            
            # è®­ç»ƒç­–ç•¥
            'cos_lr': True,  # ä½™å¼¦å­¦ä¹ ç‡è¡°å‡
            'warmup_epochs': 3.0,  # çƒ­èº«è½®æ•°
            'warmup_momentum': 0.8,
            'close_mosaic': 10,  # æœ€å10è½®å…³é—­mosaic
            
            # è®¾å¤‡é…ç½®
            'device': self.device,
            'workers': 8,  # æ•°æ®åŠ è½½çº¿ç¨‹
            
            # ä¿å­˜é…ç½®
            'save': True,
            'save_period': 10,  # æ¯10è½®ä¿å­˜ä¸€æ¬¡
            'exist_ok': True,  # è¦†ç›–ç°æœ‰è¿è¡Œ
            'project': str(self.project_dir / "results"),
            'name': f"yolov8{self.config.MODEL_SIZE}_fire_detection",
            
            # éªŒè¯é…ç½®
            'val': True,  # è®­ç»ƒæœŸé—´éªŒè¯
            'cache': False,  # æ•°æ®ç¼“å­˜ (Trueå¯åŠ é€Ÿä½†éœ€è¦æ›´å¤šå†…å­˜)
        }
        
        return args
    
    def train(self):
        """å¼€å§‹è®­ç»ƒ"""
        print("\nğŸš€ å¼€å§‹æ¨¡å‹è®­ç»ƒ...")
        
        # åˆ›å»ºæ¨¡å‹
        self.create_model()
        
        # è®¾ç½®è®­ç»ƒå‚æ•°
        train_args = self.setup_training_arguments()
        
        try:
            # å¼€å§‹è®­ç»ƒ
            results = self.model.train(**train_args)
            
            print("âœ… è®­ç»ƒå®Œæˆ!")
            return results
            
        except Exception as e:
            print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
            return None
    
    def validate_model(self, model_path=None):
        """éªŒè¯æ¨¡å‹æ€§èƒ½"""
        print("\nğŸ” éªŒè¯æ¨¡å‹æ€§èƒ½...")
        
        if model_path is None:
            # è‡ªåŠ¨æ‰¾åˆ°æœ€ä½³æ¨¡å‹
            model_path = self.project_dir / "results" / f"yolov8{self.config.MODEL_SIZE}_fire_detection" / "weights" / "best.pt"
        
        if not os.path.exists(model_path):
            print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            return None
        
        try:
            # åŠ è½½æœ€ä½³æ¨¡å‹
            best_model = YOLO(str(model_path))
            
            # åœ¨éªŒè¯é›†ä¸ŠéªŒè¯
            metrics = best_model.val(
                data=str(self.dataset_path / "data.yaml"),
                split='val',
                device=self.device
            )
            
            print("ğŸ“Š éªŒè¯ç»“æœ:")
            print(f"  mAP50: {metrics.box.map50:.4f}")
            print(f"  mAP50-95: {metrics.box.map:.4f}")
            print(f"  ç²¾ç¡®åº¦: {metrics.box.mp:.4f}")
            print(f"  å¬å›ç‡: {metrics.box.mr:.4f}")
            
            return metrics
            
        except Exception as e:
            print(f"âŒ éªŒè¯å¤±è´¥: {e}")
            return None
    
    def export_model(self, model_path=None, format='onnx'):
        """å¯¼å‡ºæ¨¡å‹"""
        print(f"\nğŸ“¤ å¯¼å‡ºæ¨¡å‹ä¸º {format.upper()} æ ¼å¼...")
        
        if model_path is None:
            model_path = self.project_dir / "results" / f"yolov8{self.config.MODEL_SIZE}_fire_detection" / "weights" / "best.pt"
        
        if not os.path.exists(model_path):
            print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            return None
        
        try:
            model = YOLO(str(model_path))
            
            # å¯¼å‡ºæ¨¡å‹
            export_path = model.export(format=format, dynamic=True)
            
            print(f"âœ… æ¨¡å‹å¯¼å‡ºæˆåŠŸ: {export_path}")
            return export_path
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹å¯¼å‡ºå¤±è´¥: {e}")
            return None
    
    def run_complete_pipeline(self):
        """è¿è¡Œå®Œæ•´çš„è®­ç»ƒæµç¨‹"""
        # 1. ç¯å¢ƒæ£€æŸ¥
        if not self.check_dataset():
            return False
        
        # 2. æ•°æ®åˆ†æ
        self.analyze_dataset()
        
        # 3. å¼€å§‹è®­ç»ƒ
        results = self.train()
        if results is None:
            return False
        
        # 4. éªŒè¯æ¨¡å‹
        metrics = self.validate_model()
        if metrics is None:
            return False
        
        # 5. å¯¼å‡ºæ¨¡å‹
        export_path = self.export_model()
        
        print("\nğŸ‰ è®­ç»ƒæµç¨‹å®Œæˆ!")
        print(f"ğŸ“ æœ€ä½³æ¨¡å‹: {self.project_dir}/results/yolov8{self.config.MODEL_SIZE}_fire_detection/weights/best.pt")
        if export_path:
            print(f"ğŸ“¤ å¯¼å‡ºæ¨¡å‹: {export_path}")
        
        return True

def create_sample_data_yaml(dataset_path):
    """åˆ›å»ºç¤ºä¾‹æ•°æ®é…ç½®æ–‡ä»¶"""
    data_config = {
        'path': str(dataset_path),  # æ•°æ®é›†æ ¹ç›®å½•
        'train': 'train/images',    # è®­ç»ƒå›¾åƒè·¯å¾„
        'val': 'val/images',        # éªŒè¯å›¾åƒè·¯å¾„
        'test': 'test/images',      # æµ‹è¯•å›¾åƒè·¯å¾„ (å¯é€‰)
        
        'nc': 2,  # ç±»åˆ«æ•°
        'names': {
            0: 'fire',     # ç«ç„°
            1: 'smoke'     # çƒŸé›¾
        },
        
        # å¯é€‰: ä¸‹è½½é“¾æ¥
        'download': None
    }
    
    yaml_path = dataset_path / "data.yaml"
    with open(yaml_path, 'w') as f:
        yaml.dump(data_config, f, default_flow_style=False)
    
    print(f"âœ… åˆ›å»ºç¤ºä¾‹æ•°æ®é…ç½®: {yaml_path}")
    return yaml_path

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='æ—ç«è¯†åˆ«æ¨¡å‹è®­ç»ƒè„šæœ¬')
    parser.add_argument('--model', type=str, default='m', 
                       choices=['n', 's', 'm', 'l', 'x'],
                       help='æ¨¡å‹å¤§å° (n/s/m/l/x)')
    parser.add_argument('--epochs', type=int, default=150,
                       help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--batch-size', type=int, default=16,
                       help='æ‰¹å¤§å°')
    parser.add_argument('--img-size', type=int, default=640,
                       help='å›¾åƒå°ºå¯¸')
    parser.add_argument('--dataset', type=str, 
                       default='datasets/fire_dataset',
                       help='æ•°æ®é›†è·¯å¾„')
    parser.add_argument('--no-pretrained', action='store_true',
                       help='ä¸ä»é¢„è®­ç»ƒæ¨¡å‹å¼€å§‹')
    
    args = parser.parse_args()
    
    # æ›´æ–°é…ç½®
    config = TrainingConfig()
    config.MODEL_SIZE = args.model
    config.EPOCHS = args.epochs
    config.BATCH_SIZE = args.batch_size
    config.IMAGE_SIZE = args.img_size
    config.DATASET_DIR = args.dataset
    config.PRETRAINED_MODEL = not args.no_pretrained
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = ForestFireTrainer(config)
    
    # è¿è¡Œå®Œæ•´æµç¨‹
    success = trainer.run_complete_pipeline()
    
    if not success:
        print("\nâŒ è®­ç»ƒæµç¨‹å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ä¿¡æ¯")
        return 1
    
    return 0

if __name__ == "__main__":
    # ç›´æ¥è¿è¡Œè®­ç»ƒ
    config = TrainingConfig()
    trainer = ForestFireTrainer(config)
    trainer.run_complete_pipeline()
    
    # æˆ–è€…ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°
    # main()
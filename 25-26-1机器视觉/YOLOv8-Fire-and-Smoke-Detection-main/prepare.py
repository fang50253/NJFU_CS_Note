"""
æ•°æ®é›†å‡†å¤‡è„šæœ¬ - prepare_dataset.py
"""

import os
import shutil
from pathlib import Path
import yaml

def create_dataset_structure(base_path):
    """åˆ›å»ºæ•°æ®é›†ç›®å½•ç»“æ„"""
    directories = [
        base_path / "train" / "images",
        base_path / "train" / "labels", 
        base_path / "val" / "images",
        base_path / "val" / "labels",
        base_path / "test" / "images",
        base_path / "test" / "labels"
    ]
    
    for directory in directories:
        directory.mkdir(parents=True, exist_ok=True)
        print(f"âœ… åˆ›å»ºç›®å½•: {directory}")
    
    return base_path

def create_data_yaml(dataset_path, class_names):
    """åˆ›å»ºæ•°æ®é…ç½®æ–‡ä»¶"""
    data_config = {
        'path': str(dataset_path),
        'train': 'train/images',
        'val': 'val/images', 
        'test': 'test/images',
        'nc': len(class_names),
        'names': class_names
    }
    
    yaml_path = dataset_path / "data.yaml"
    with open(yaml_path, 'w') as f:
        yaml.dump(data_config, f, default_flow_style=False)
    
    print(f"âœ… åˆ›å»ºæ•°æ®é…ç½®: {yaml_path}")
    return yaml_path

def split_dataset(image_dir, label_dir, train_ratio=0.7, val_ratio=0.2, test_ratio=0.1):
    """åˆ†å‰²æ•°æ®é›†"""
    # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶
    image_files = list(Path(image_dir).glob("*.*"))
    image_files = [f for f in image_files if f.suffix.lower() in ['.jpg', '.jpeg', '.png', '.bmp']]
    
    # éšæœºæ‰“ä¹±
    import random
    random.shuffle(image_files)
    
    # è®¡ç®—åˆ†å‰²ç‚¹
    total = len(image_files)
    train_end = int(total * train_ratio)
    val_end = train_end + int(total * val_ratio)
    
    # åˆ†å‰²æ•°æ®é›†
    train_files = image_files[:train_end]
    val_files = image_files[train_end:val_end]
    test_files = image_files[val_end:]
    
    print(f"ğŸ“Š æ•°æ®é›†åˆ†å‰²:")
    print(f"  è®­ç»ƒé›†: {len(train_files)} å›¾åƒ")
    print(f"  éªŒè¯é›†: {len(val_files)} å›¾åƒ") 
    print(f"  æµ‹è¯•é›†: {len(test_files)} å›¾åƒ")
    
    return train_files, val_files, test_files

def prepare_fire_dataset():
    """å‡†å¤‡æ—ç«æ•°æ®é›†"""
    base_dir = Path.home() / "ForestFireDetection" / "datasets" / "fire_dataset"
    
    print("ğŸ”¥ å‡†å¤‡æ—ç«æ£€æµ‹æ•°æ®é›†...")
    
    # åˆ›å»ºç›®å½•ç»“æ„
    dataset_path = create_dataset_structure(base_dir)
    
    # åˆ›å»ºæ•°æ®é…ç½® (æ—ç«æ£€æµ‹é€šå¸¸æœ‰2ä¸ªç±»åˆ«)
    class_names = {
        0: 'fire',    # ç«ç„°
        1: 'smoke'    # çƒŸé›¾
    }
    
    create_data_yaml(dataset_path, class_names)
    
    print(f"""
    ğŸ¯ æ•°æ®é›†ç»“æ„å·²åˆ›å»º!
    
    è¯·å°†æ‚¨çš„æ•°æ®æŒ‰ä»¥ä¸‹æ–¹å¼ç»„ç»‡:
    
    {base_dir}/
    â”œâ”€â”€ data.yaml
    â”œâ”€â”€ train/
    â”‚   â”œâ”€â”€ images/     # æ”¾ç½®è®­ç»ƒå›¾åƒ
    â”‚   â””â”€â”€ labels/     # æ”¾ç½®YOLOæ ¼å¼çš„æ ‡æ³¨æ–‡ä»¶
    â”œâ”€â”€ val/
    â”‚   â”œâ”€â”€ images/     # æ”¾ç½®éªŒè¯å›¾åƒ  
    â”‚   â””â”€â”€ labels/     # æ”¾ç½®YOLOæ ¼å¼çš„æ ‡æ³¨æ–‡ä»¶
    â””â”€â”€ test/
        â”œâ”€â”€ images/     # æ”¾ç½®æµ‹è¯•å›¾åƒ
        â””â”€â”€ labels/     # æ”¾ç½®YOLOæ ¼å¼çš„æ ‡æ³¨æ–‡ä»¶
    
    ğŸ“ æ ‡æ³¨æ–‡ä»¶æ ¼å¼ (YOLO):
      æ¯è¡Œ: <class_id> <x_center> <y_center> <width> <height>
      åæ ‡éœ€è¦å½’ä¸€åŒ–åˆ° [0, 1]
    """)

if __name__ == "__main__":
    prepare_fire_dataset()
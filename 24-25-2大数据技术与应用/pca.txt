#  -*- coding:utf-8 -*-
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn import datasets
class DimensionValueError(ValueError):
     pass
class PCA(object):
    def __init__(self, x, n_components=None):
        self.x = x
        self.dimension = x.shape[1]
        if n_components and n_components > self.dimension:
            raise DimensionValueError("n_components error")
        self.n_components = n_components
    def cov(self):
        x_T =np.transpose(self.x)
        x_cov=np.cov(x_T)
        return x_cov
    def get_feature(self):
        x_cov = self.cov()
        a,b=np.linalg.eig(x_cov)
        m = a.shape[0]
        c = np.vstack((a.reshape(1,m),b))
        c_df=pd.DataFrame(c)
        c_df_sort=c_df.sort_values(by=0,axis=1,ascending=False)
        return c_df_sort
       
    def explained_variance_(self):
        c_df_sort=self.get_feature()
        return c_df_sort.values[0,:]
    def paint_variance_(self):
        explained_variance_ = self.explained_variance_()
        plt.figure()
        plt.plot(explained_variance_,'r')
        plt.xlabel('n_components',fontsize=16)
        plt.ylabel('explained_variance_',fontsize=16)
        plt.show()
    def explained_variance_ratio(self):
        c_df_sort=self.get_feature()
        variance = self.explained_variance_()
        variance_sum=sum(variance)
        variance_ratio = variance/variance_sum
        return variance_ratio
    def reduce_dimension(self):
        c_df_sort=self.get_feature()
        variance = self.explained_variance_()
        if self.n_components:
            p=c_df_sort.values[1:,0:self.n_components]
            y=np.dot(np.transpose(p),np.transpose(self.x))
            return np.transpose(y)
        variance_sum=sum(variance)
        variance_ratio = variance/variance_sum
        variance_contribution =0
        for r in range(self.dimension):
            variance_contribution+=variance_ratio[r]
            if variance_contribution >=0.95:
                break
        p=c_df_sort.values[1:,0:r+1]
        y=np.dot(np.transpose(p),np.transpose(self.x))
        return np.transpose(y)


if __name__=='__main__':
    digits=datasets.load_digits()
    
    x=digits.data
    y=digits.target
    #print(x[0].reshape(8,8))
    plt.figure(figsize=(1,1))
    plt.imshow(x[0].reshape(8,8),cmap='Greys',interpolation='nearest')
    plt.show()
    pca=PCA(x)
    pca.paint_variance_()
    reduce=pca.reduce_dimension()
    plt.figure()
    plt.scatter(reduce[:50,0],reduce[:50,1])
    plt.show()
    print(y[0:50])
    s=pd.Series(y[0:50])
    print(s.value_counts())
    
    biddingdata = pd.read_table('./data/shill_bidding.csv', sep=',', encoding='gbk')
    print(biddingdata.shape)
    x1=biddingdata.iloc[:,:-1]
    y1=biddingdata.iloc[:,-1]
    pca1=PCA(x1)
    pca1.paint_variance_()
    reduce1=pca.reduce_dimension()
    plt.figure()
    plt.scatter(reduce1[:50,0],reduce1[:50,1])
    plt.show()
    
    from sklearn.decomposition import PCA
    pca_model = PCA(n_components=64).fit(x) 
    model_data=pca_model.transform(x)
    plt.figure()
    plt.scatter(model_data[:50,0],model_data[:50,1])
    plt.show()
    #print(pca.explained_variance_ratio())
    plt.figure()
    plt.plot(pca_model.singular_values_,'r')
    plt.xlabel('n_components',fontsize=16)
    plt.ylabel('explained_variance_',fontsize=16)
    plt.show()